{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d819397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "DATA_PATH = \"data\"\n",
    "def load_documents():\n",
    "    loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02092dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 13 documents.\n",
      "First document text: page_content='Ali Lazraq \n",
      " Data Scientist \n",
      " üìß lazraqali08@gmail.com |  Ali Lazraq  | üìç Casablanca, Morocco |  üìû   +212 623792204 \n",
      " EXPERIENCES \n",
      " CIH BANK  Casablanca, Morocco \n",
      " Data Science  Jan 2025 - Current \n",
      " ‚óè  Developed a full-scale churn prediction system using LightGBM, achieving 90.42% recall prioritizing client retention. \n",
      " ‚óè  Engineered end-to-end modular Python pipelines for data extraction via Dremio, preprocessing, feature engineering, and \n",
      " model deployment. \n",
      " ‚óè  Designed interactive Streamlit dashboard for business stakeholders to visualize churn insights and intervention plans. \n",
      " ‚óè  Implemented SHAP for model interpretability and MLflow for rigorous experiment tracking and version control. \n",
      " CAPSTONE PROJECT  Ifrane, Morocco \n",
      " IoT-Based Fleet Management & Driver Monitoring  Sep 2024 - Dec 2024 \n",
      " ‚óè  Built a real-time fleet management system integrating Teltonika FM5300, React, Spring Boot, and MySQL. \n",
      " ‚óè  Directed the integration of GPS tracking, geofencing, and predictive maintenance features to improve fleet efficiency. \n",
      " ‚óè  Drove business analytics initiatives to identify cost-saving opportunities and enhance operational decision-making. \n",
      " ‚óè  Designed and maintained a live dashboard for real-time alerts, KPIs, and vehicle diagnostics. \n",
      " ‚óè  Integrated machine learning models to optimize fleet costs and route planning. \n",
      " MENTOR Center of Learning Excellence, AUI  Ifrane, Morocco \n",
      " Part-time job  Sep 2024 - Dec 2024 \n",
      " ‚óè  Mentored incoming students in academic planning, leadership, and soft skill development. \n",
      " ‚óè  Acted as a peer leader and first-line support for academic and career-related queries. \n",
      " CIH BANKATHON COMPETITION  Ifrane, Morocco \n",
      " Data Science Participant  Nov 2024 \n",
      " ‚óè  Led a team in designing a customer segmentation pipeline using clustering to personalize CIH Bank‚Äôs product offers.. \n",
      " ‚óè  Developed and showcased a complete Streamlit web app that earned executive recognition and resulted an internship offer. \n",
      " LEYTON  Casablanca, Morocco \n",
      " Data Science & Software Engineering Intern  Summer 2023 \n",
      " ‚óè  Conducted strategic client density analyses using Power BI, providing the executive team with actionable insights. \n",
      " ‚óè  Independently designed and deployed a Chrome Extension using JavaScript to enable real-time consultant notifications, \n",
      " reducing average response time. \n",
      " INFOMINEO RESEARCH CASE COMPETITION  Ifrane, Morocco \n",
      " Participant  Oct 2023 \n",
      " ‚óè  Represented the Computer Science track in a multidisciplinary team tasked with building a data-informed solution for a \n",
      " global business challenge. \n",
      " ‚óè  Gained experience in cross-cultural communication, international business models, and innovation under pressure. \n",
      " EDUCATION \n",
      " Al Akhawayn University  Ifrane, Morocco \n",
      " Bachelor of  Science in Computer Science  with a Minor in  Business Administration  .  Sep 2020 -  Dec 2024 \n",
      " Aspiring Data Scientist motivated by real-world challenges at the intersection of data and impact. Passionate about interdisciplinary \n",
      " collaboration, international exchange, and using technology to improve decision-making in public and private sectors. \n",
      " EXTRACURRICULAR ACTIVITIES \n",
      " AMERICAN FOOTBALL TEAM - ATLAS LIONS AUI:  Ifrane, Morocco \n",
      " Played competitive matches, enhancing teamwork & strategic thinking.  Sep 2023 ‚Äì Dec 2024 \n",
      " PRESIDENT - NAUTICAL SURFING CLUB AUI:  Ifrane, Morocco \n",
      " Organized and managed multiple surfing trips & sponsorships.  Jan 2023 ‚Äì Sep 2024 \n",
      " SKILLS, ACTIVITIES & INTERESTS \n",
      " Languages:  Arabic, English, French \n",
      " Programming:  Python, SQL, JavaScript, Java, C \n",
      " Data Science & ML:  LightGBM, XGBoost, SHAP, MLflow, Streamlit, Pandas, NumPy, Scikit-learn, Power BI \n",
      " Frameworks & Tools:  React, Spring Boot, Docker, FastAPI, Git, Dremio, Web Scraping, Streamlit \n",
      " Soft Skills :  Critical Thinking, Leadership, Problem-Solving, Communication, Teamwork, Agile Mindset' metadata={'producer': '4-Heights‚Ñ¢ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36 OPR/118.0.0.0', 'creationdate': '2025-05-16T10:24:08+00:00', 'title': 'Ali_Cv - Google\\xa0Docs', 'moddate': '2025-05-16T10:33:59+00:00', 'source': 'data\\\\Ali_Lazraq___eng_CV (1).pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents()\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "print(f\"First document text: {documents[0]}\")  # Print first 100 characters of the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc626b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "def split_documents(documents: list[Document]):\n",
    "    # Create a text splitter that splits documents into chunks of 800 characters with 80 characters overlap\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,           # Maximum size of each chunk\n",
    "        chunk_overlap=80,         # Number of overlapping characters between chunks\n",
    "        length_function=len,      # Function to measure the length of text (here, using len)\n",
    "        is_separator_regex=False  # Indicates that the separator is not a regex\n",
    "    )\n",
    "    # Split the input documents into smaller chunks using the text splitter\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    # Return the list of split document chunks\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce38a102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 46 chunks.\n",
      "First chunk text: page_content='Ali Lazraq \n",
      " Data Scientist \n",
      " üìß lazraqali08@gmail.com |  Ali Lazraq  | üìç Casablanca, Morocco |  üìû   +212 623792204 \n",
      " EXPERIENCES \n",
      " CIH BANK  Casablanca, Morocco \n",
      " Data Science  Jan 2025 - Current \n",
      " ‚óè  Developed a full-scale churn prediction system using LightGBM, achieving 90.42% recall prioritizing client retention. \n",
      " ‚óè  Engineered end-to-end modular Python pipelines for data extraction via Dremio, preprocessing, feature engineering, and \n",
      " model deployment. \n",
      " ‚óè  Designed interactive Streamlit dashboard for business stakeholders to visualize churn insights and intervention plans. \n",
      " ‚óè  Implemented SHAP for model interpretability and MLflow for rigorous experiment tracking and version control. \n",
      " CAPSTONE PROJECT  Ifrane, Morocco' metadata={'producer': '4-Heights‚Ñ¢ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36 OPR/118.0.0.0', 'creationdate': '2025-05-16T10:24:08+00:00', 'title': 'Ali_Cv - Google\\xa0Docs', 'moddate': '2025-05-16T10:33:59+00:00', 'source': 'data\\\\Ali_Lazraq___eng_CV (1).pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(documents)\n",
    "print(f\"Split into {len(chunks)} chunks.\")\n",
    "print(f\"First chunk text: {chunks[0]}\")  # Print first 100 characters of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a08e6700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: mistral\n",
      "Embedding function: base_url='http://localhost:11434' model='mistral' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alila\\AppData\\Local\\Temp\\ipykernel_34624\\938370009.py:5: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_function = OllamaEmbeddings(model=\"mistral\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "\n",
    "def get_embedding_function():\n",
    "    # Create an instance of the OllamaEmbeddings class with the model name \"mistral\"\n",
    "    embedding_function = OllamaEmbeddings(model=\"mistral\")\n",
    "    # Print the model name used for embeddings\n",
    "    print(f\"Using model: {embedding_function.model}\")\n",
    "    # Return the embedding function\n",
    "    return embedding_function\n",
    "embedding_function = get_embedding_function()\n",
    "print(f\"Embedding function: {embedding_function}\")  # Print the embedding function details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7d697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First chunk ID: data\\Ali_Lazraq___eng_CV (1).pdf:0:0\n"
     ]
    }
   ],
   "source": [
    "def calculate_chunk_ids(chunks):\n",
    "\n",
    "    # This will create IDs like \"data/monopoly.pdf:6:2\"\n",
    "    # Page Source : Page Number : Chunk Index\n",
    "\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        # If the page ID is the same as the last one, increment the index.\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "\n",
    "        # Calculate the chunk ID.\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "\n",
    "        # Add it to the page meta-data.\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks\n",
    "chunks = calculate_chunk_ids(chunks)\n",
    "print(f\"First chunk ID: {chunks[0].metadata['id']}\")  # Print the ID of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d1cc3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: mistral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alila\\AppData\\Local\\Temp\\ipykernel_34624\\3365163514.py:8: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing documents in DB: 40\n",
      "üëâ Adding new documents: 6\n",
      "Number of documents in DB: 46\n",
      "First document ID in DB: data\\monopoly.pdf:0:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alila\\AppData\\Local\\Temp\\ipykernel_34624\\3365163514.py:30: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "\n",
    "    CHROMA_PATH = \"chroma\"  # Path to the Chroma database\n",
    "    \n",
    "    # Load the existing database.\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH, embedding_function=get_embedding_function()\n",
    "    )\n",
    "\n",
    "    # Calculate Page IDs.\n",
    "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n",
    "    # Add or Update the documents.\n",
    "    existing_items = db.get(include=[])  # IDs are always included by default\n",
    "    existing_ids = set(existing_items[\"ids\"])\n",
    "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
    "\n",
    "    # Only add documents that don't exist in the DB.\n",
    "    new_chunks = []\n",
    "    for chunk in chunks_with_ids:\n",
    "        if chunk.metadata[\"id\"] not in existing_ids:\n",
    "            new_chunks.append(chunk)\n",
    "\n",
    "    if len(new_chunks):\n",
    "        print(f\"üëâ Adding new documents: {len(new_chunks)}\")\n",
    "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "        db.persist()\n",
    "    else:\n",
    "        print(\"‚úÖ No new documents to add\")\n",
    "\n",
    "    # Return the database object\n",
    "    return db\n",
    "db = add_to_chroma(chunks)\n",
    "print(f\"Number of documents in DB: {len(db.get(include=[])['ids'])}\")  # Print the number of documents in the database\n",
    "print(f\"First document ID in DB: {db.get(include=[])['ids'][0]}\")  # Print the ID of the first document in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08bff242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First document ID in DB: data\\ticket_to_ride.pdf:3:4\n"
     ]
    }
   ],
   "source": [
    "print(f\"First document ID in DB: {db.get(include=[])['ids'][39]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "130e9982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: mistral\n",
      "Number of existing documents in DB: 46\n",
      "‚úÖ No new documents to add\n"
     ]
    }
   ],
   "source": [
    "db = add_to_chroma(chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
